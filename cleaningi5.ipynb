{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Intel-Unnathi-Intership-Program/Product_Sentiment_Analysis/blob/main/cleaningi5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7f3995e-244b-43d2-a5ca-9e14bb46e1b3",
      "metadata": {
        "id": "c7f3995e-244b-43d2-a5ca-9e14bb46e1b3",
        "outputId": "3bb83e25-f6ff-4634-dd8c-8ec505a816d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Data:\n",
            "  Processor                                                URL  review_rating  \\\n",
            "0        i5  https://www.amazon.in/Intel-Generation-Desktop...            5.0   \n",
            "1        i5  https://www.amazon.in/Intel-Generation-Desktop...            5.0   \n",
            "2        i5  https://www.amazon.in/Intel-Generation-Desktop...            5.0   \n",
            "3        i5  https://www.amazon.in/Intel-Generation-Desktop...            4.0   \n",
            "4        i5  https://www.amazon.in/Intel-Generation-Desktop...            5.0   \n",
            "\n",
            "                                         review_body  \n",
            "0  The processor was very power efficient i devel...  \n",
            "1  best budget range and entry level processor ou...  \n",
            "2  This processor is great mid to high range budg...  \n",
            "3  This will not work without graphic card, So be...  \n",
            "4     Thanku Appario you send me best cpu\\nRead more  \n",
            "Cleaned Data:\n",
            "  Processor                                                URL  review_rating  \\\n",
            "0        i5  https://www.amazon.in/Intel-Generation-Desktop...            5.0   \n",
            "1        i5  https://www.amazon.in/Intel-Generation-Desktop...            5.0   \n",
            "2        i5  https://www.amazon.in/Intel-Generation-Desktop...            5.0   \n",
            "3        i5  https://www.amazon.in/Intel-Generation-Desktop...            4.0   \n",
            "4        i5  https://www.amazon.in/Intel-Generation-Desktop...            5.0   \n",
            "\n",
            "                                         review_body  \n",
            "0  processor power efficient develop android apps...  \n",
            "1  best budget range entry level processor get go...  \n",
            "2  processor great mid high range budget build lo...  \n",
            "3            work without graphic card careful order  \n",
            "4                       thanku appario send best cpu  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Ananya\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\Ananya\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Ensure the required NLTK data packages are downloaded\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Load the dataset\n",
        "file_path = r\"C:\\Users\\Ananya\\Documents\\Intel Dataset\\i5_reviews.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(\"Original Data:\")\n",
        "print(df.head())\n",
        "\n",
        "# Data Cleaning Steps\n",
        "\n",
        "# 1. Handling missing values\n",
        "# Drop rows with any missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# 2. Removing duplicates\n",
        "# Drop duplicate rows\n",
        "#df.drop_duplicates(inplace=True)\n",
        "\n",
        "# 3. Normalizing text (assuming there's a 'review_body' column)\n",
        "# Convert column to string type to handle non-string values\n",
        "df['review_body'] = df['review_body'].astype(str)\n",
        "\n",
        "# Convert text to lowercase\n",
        "df['review_body'] = df['review_body'].str.lower()\n",
        "\n",
        "# Remove punctuation and special characters\n",
        "df['review_body'] = df['review_body'].str.replace(r'[^\\w\\s]', '', regex=True)\n",
        "\n",
        "# Remove numbers\n",
        "df['review_body'] = df['review_body'].str.replace(r'\\d+', '', regex=True)\n",
        "\n",
        "# Initialize the WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Remove stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    # Remove \"read more\"\n",
        "    text = text.replace('read more', '')\n",
        "    words = text.split()\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    words = [lemmatizer.lemmatize(word, pos='v') for word in words]  # Apply lemmatization\n",
        "    return ' '.join(words)\n",
        "\n",
        "df['review_body'] = df['review_body'].apply(clean_text)\n",
        "\n",
        "# Temporarily save the cleaned dataset to a new file\n",
        "temp_file_path = r\"C:\\Users\\Ananya\\Documents\\Intel Dataset\\temp_i5_reviews.csv\"\n",
        "df.to_csv(temp_file_path, index=False)\n",
        "\n",
        "# Display the first few rows of the cleaned dataset\n",
        "print(\"Cleaned Data:\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4adc05f3-6bd6-4142-88f8-4b5e56eb4872",
      "metadata": {
        "id": "4adc05f3-6bd6-4142-88f8-4b5e56eb4872"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}