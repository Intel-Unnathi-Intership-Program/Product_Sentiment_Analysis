{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "                         Product  review_rating  \\\n",
      "0  Intel Core i3-13100 Processor              4   \n",
      "1  Intel Core i3-13100 Processor              5   \n",
      "2  Intel Core i3-13100 Processor              5   \n",
      "3  Intel Core i3-13100 Processor              5   \n",
      "4  Intel Core i3-13100 Processor              5   \n",
      "\n",
      "                                         review_body  \n",
      "0  13th generation intel core i3 processors total...  \n",
      "1                                            perfect  \n",
      "2  didnt mention processor came heatsink bought b...  \n",
      "3  great entry level processor works like expensi...  \n",
      "4                                                top  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ananya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Ananya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Data:\n",
      "                         Product  review_rating  \\\n",
      "0  Intel Core i3-13100 Processor              4   \n",
      "1  Intel Core i3-13100 Processor              5   \n",
      "2  Intel Core i3-13100 Processor              5   \n",
      "3  Intel Core i3-13100 Processor              5   \n",
      "4  Intel Core i3-13100 Processor              5   \n",
      "\n",
      "                                         review_body  \n",
      "0  th generation intel core processors total core...  \n",
      "1                                            perfect  \n",
      "2  didnt mention processor come heatsink buy bett...  \n",
      "3  great entry level processor work like expensiv...  \n",
      "4                                                top  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Ensure the required NLTK data packages are downloaded\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\Ananya\\Documents\\Intel Dataset\\raw_dataset.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"Original Data:\")\n",
    "print(df.head())\n",
    "\n",
    "# Data Cleaning Steps\n",
    "\n",
    "# 1. Handling missing values\n",
    "# Drop rows with any missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# 2. Removing duplicates\n",
    "# Drop duplicate rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# 3. Normalizing text (assuming there's a 'review_body' column)\n",
    "# Convert column to string type to handle non-string values\n",
    "df['review_body'] = df['review_body'].astype(str)\n",
    "\n",
    "# Convert text to lowercase\n",
    "df['review_body'] = df['review_body'].str.lower()\n",
    "\n",
    "# Remove punctuation and special characters\n",
    "df['review_body'] = df['review_body'].str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "\n",
    "# Remove numbers\n",
    "df['review_body'] = df['review_body'].str.replace(r'\\d+', '', regex=True)\n",
    "\n",
    "# Initialize the WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove \"read more\"\n",
    "    text = text.replace('read more', '')\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    words = [lemmatizer.lemmatize(word, pos='v') for word in words]  # Apply lemmatization\n",
    "    return ' '.join(words)\n",
    "\n",
    "df['review_body'] = df['review_body'].apply(clean_text)\n",
    "\n",
    "# Temporarily save the cleaned dataset to a new file\n",
    "temp_file_path = r\"C:\\Users\\Ananya\\Documents\\Intel Dataset\\dataset.csv\"\n",
    "df.to_csv(temp_file_path, index=False)\n",
    "\n",
    "# Display the first few rows of the cleaned dataset\n",
    "print(\"Cleaned Data:\")\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
