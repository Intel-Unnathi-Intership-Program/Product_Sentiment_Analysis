{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Intel-Unnathi-Intership-Program/Product_Sentiment_Analysis/blob/main/cleaningi7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYBi-jFYYRqk",
        "outputId": "e52f4c82-bb16-4e8d-9412-20f1a77a7c72"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Ananya\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\Ananya\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Data:\n",
            "  Product                                                URL  review_rating  \\\n",
            "0      i7  https://www.amazon.com/Intel-i7-12700K-Desktop...              5   \n",
            "1      i7  https://www.amazon.com/Intel-i7-12700K-Desktop...              5   \n",
            "2      i7  https://www.amazon.com/Intel-i7-12700K-Desktop...              5   \n",
            "3      i7  https://www.amazon.com/Intel-i7-12700K-Desktop...              5   \n",
            "4      i7  https://www.amazon.com/Intel-i7-12700K-Desktop...              5   \n",
            "\n",
            "                                         review_body  \n",
            "0  I upgraded to this CPU after some HEAVY resear...  \n",
            "1  This cpu is very powerful and can run games (w...  \n",
            "2  Great CPU, put it in a new personal gaming rig...  \n",
            "3  The Intel Core i7-12700K has significantly enh...  \n",
            "4  This is my first intel build coming from past ...  \n",
            "Cleaned Data:\n",
            "  Product                                                URL  review_rating  \\\n",
            "0      i7  https://www.amazon.com/Intel-i7-12700K-Desktop...              5   \n",
            "1      i7  https://www.amazon.com/Intel-i7-12700K-Desktop...              5   \n",
            "2      i7  https://www.amazon.com/Intel-i7-12700K-Desktop...              5   \n",
            "3      i7  https://www.amazon.com/Intel-i7-12700K-Desktop...              5   \n",
            "4      i7  https://www.amazon.com/Intel-i7-12700K-Desktop...              5   \n",
            "\n",
            "                                         review_body  \n",
            "0  upgrade cpu heavy research ask reddit intel am...  \n",
            "1  cpu powerful run game pair good graphics card ...  \n",
            "2  great cpu put new personal game rig hit ghz bo...  \n",
            "3  intel core ik significantly enhance game produ...  \n",
            "4  first intel build come past amd build ryzen fx...  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Ensure the required NLTK data packages are downloaded\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Load the dataset\n",
        "file_path = r\"C:\\Users\\Ananya\\Documents\\Intel Dataset\\dataset_i7_intel.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(\"Original Data:\")\n",
        "print(df.head())\n",
        "\n",
        "# Data Cleaning Steps\n",
        "\n",
        "# 1. Handling missing values\n",
        "# Drop rows with any missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# 2. Removing duplicates\n",
        "# Drop duplicate rows\n",
        "#df.drop_duplicates(inplace=True)\n",
        "\n",
        "# 3. Normalizing text (assuming there's a 'review_body' column)\n",
        "# Convert column to string type to handle non-string values\n",
        "df['review_body'] = df['review_body'].astype(str)\n",
        "\n",
        "# Convert text to lowercase\n",
        "df['review_body'] = df['review_body'].str.lower()\n",
        "\n",
        "# Remove punctuation and special characters\n",
        "df['review_body'] = df['review_body'].str.replace(r'[^\\w\\s]', '', regex=True)\n",
        "\n",
        "# Remove numbers\n",
        "df['review_body'] = df['review_body'].str.replace(r'\\d+', '', regex=True)\n",
        "\n",
        "# Initialize the WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Remove stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    # Remove \"read more\"\n",
        "    text = text.replace('read more', '')\n",
        "    words = text.split()\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    words = [lemmatizer.lemmatize(word, pos='v') for word in words]  # Apply lemmatization\n",
        "    return ' '.join(words)\n",
        "\n",
        "df['review_body'] = df['review_body'].apply(clean_text)\n",
        "\n",
        "# Temporarily save the cleaned dataset to a new file\n",
        "temp_file_path = r\"C:\\Users\\Ananya\\Documents\\Intel Dataset\\temp_dataset_i7_intel.csv\"\n",
        "df.to_csv(temp_file_path, index=False)\n",
        "\n",
        "# Display the first few rows of the cleaned dataset\n",
        "print(\"Cleaned Data:\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1K2t2xc8YRqo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}